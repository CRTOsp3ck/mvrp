// Code generated by SQLBoiler 4.16.2 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package base

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/null/v8"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/sqlboiler/v4/types"
	"github.com/volatiletech/strmangle"
)

// BaseDocumentItem is an object representing the database table.
type BaseDocumentItem struct {
	ID                     int               `boil:"id" json:"id" toml:"id" yaml:"id"`
	CreatedAt              time.Time         `boil:"created_at" json:"created_at" toml:"created_at" yaml:"created_at"`
	UpdatedAt              time.Time         `boil:"updated_at" json:"updated_at" toml:"updated_at" yaml:"updated_at"`
	DeletedAt              null.Time         `boil:"deleted_at" json:"deleted_at,omitempty" toml:"deleted_at" yaml:"deleted_at,omitempty"`
	BaseDocumentID         int               `boil:"base_document_id" json:"base_document_id" toml:"base_document_id" yaml:"base_document_id"`
	InventoryID            null.Int          `boil:"inventory_id" json:"inventory_id,omitempty" toml:"inventory_id" yaml:"inventory_id,omitempty"`
	Quantity               types.NullDecimal `boil:"quantity" json:"quantity,omitempty" toml:"quantity" yaml:"quantity,omitempty"`
	UnitPrice              types.NullDecimal `boil:"unit_price" json:"unit_price,omitempty" toml:"unit_price" yaml:"unit_price,omitempty"`
	UnitDiscountAmount     types.NullDecimal `boil:"unit_discount_amount" json:"unit_discount_amount,omitempty" toml:"unit_discount_amount" yaml:"unit_discount_amount,omitempty"`
	TotalDiscountAmountGen types.NullDecimal `boil:"total_discount_amount_gen" json:"total_discount_amount_gen,omitempty" toml:"total_discount_amount_gen" yaml:"total_discount_amount_gen,omitempty"`
	DiscountRateGen        types.NullDecimal `boil:"discount_rate_gen" json:"discount_rate_gen,omitempty" toml:"discount_rate_gen" yaml:"discount_rate_gen,omitempty"`
	UnitTaxAmount          types.NullDecimal `boil:"unit_tax_amount" json:"unit_tax_amount,omitempty" toml:"unit_tax_amount" yaml:"unit_tax_amount,omitempty"`
	TotalTaxAmountGen      types.NullDecimal `boil:"total_tax_amount_gen" json:"total_tax_amount_gen,omitempty" toml:"total_tax_amount_gen" yaml:"total_tax_amount_gen,omitempty"`
	TaxRateGen             types.NullDecimal `boil:"tax_rate_gen" json:"tax_rate_gen,omitempty" toml:"tax_rate_gen" yaml:"tax_rate_gen,omitempty"`
	UnitShippingFees       types.NullDecimal `boil:"unit_shipping_fees" json:"unit_shipping_fees,omitempty" toml:"unit_shipping_fees" yaml:"unit_shipping_fees,omitempty"`
	TotalShippingFeesGen   types.NullDecimal `boil:"total_shipping_fees_gen" json:"total_shipping_fees_gen,omitempty" toml:"total_shipping_fees_gen" yaml:"total_shipping_fees_gen,omitempty"`
	FinalUnitPriceGen      types.NullDecimal `boil:"final_unit_price_gen" json:"final_unit_price_gen,omitempty" toml:"final_unit_price_gen" yaml:"final_unit_price_gen,omitempty"`
	TotalSalePriceGen      types.NullDecimal `boil:"total_sale_price_gen" json:"total_sale_price_gen,omitempty" toml:"total_sale_price_gen" yaml:"total_sale_price_gen,omitempty"`

	R *baseDocumentItemR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L baseDocumentItemL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var BaseDocumentItemColumns = struct {
	ID                     string
	CreatedAt              string
	UpdatedAt              string
	DeletedAt              string
	BaseDocumentID         string
	InventoryID            string
	Quantity               string
	UnitPrice              string
	UnitDiscountAmount     string
	TotalDiscountAmountGen string
	DiscountRateGen        string
	UnitTaxAmount          string
	TotalTaxAmountGen      string
	TaxRateGen             string
	UnitShippingFees       string
	TotalShippingFeesGen   string
	FinalUnitPriceGen      string
	TotalSalePriceGen      string
}{
	ID:                     "id",
	CreatedAt:              "created_at",
	UpdatedAt:              "updated_at",
	DeletedAt:              "deleted_at",
	BaseDocumentID:         "base_document_id",
	InventoryID:            "inventory_id",
	Quantity:               "quantity",
	UnitPrice:              "unit_price",
	UnitDiscountAmount:     "unit_discount_amount",
	TotalDiscountAmountGen: "total_discount_amount_gen",
	DiscountRateGen:        "discount_rate_gen",
	UnitTaxAmount:          "unit_tax_amount",
	TotalTaxAmountGen:      "total_tax_amount_gen",
	TaxRateGen:             "tax_rate_gen",
	UnitShippingFees:       "unit_shipping_fees",
	TotalShippingFeesGen:   "total_shipping_fees_gen",
	FinalUnitPriceGen:      "final_unit_price_gen",
	TotalSalePriceGen:      "total_sale_price_gen",
}

var BaseDocumentItemTableColumns = struct {
	ID                     string
	CreatedAt              string
	UpdatedAt              string
	DeletedAt              string
	BaseDocumentID         string
	InventoryID            string
	Quantity               string
	UnitPrice              string
	UnitDiscountAmount     string
	TotalDiscountAmountGen string
	DiscountRateGen        string
	UnitTaxAmount          string
	TotalTaxAmountGen      string
	TaxRateGen             string
	UnitShippingFees       string
	TotalShippingFeesGen   string
	FinalUnitPriceGen      string
	TotalSalePriceGen      string
}{
	ID:                     "base_document_item.id",
	CreatedAt:              "base_document_item.created_at",
	UpdatedAt:              "base_document_item.updated_at",
	DeletedAt:              "base_document_item.deleted_at",
	BaseDocumentID:         "base_document_item.base_document_id",
	InventoryID:            "base_document_item.inventory_id",
	Quantity:               "base_document_item.quantity",
	UnitPrice:              "base_document_item.unit_price",
	UnitDiscountAmount:     "base_document_item.unit_discount_amount",
	TotalDiscountAmountGen: "base_document_item.total_discount_amount_gen",
	DiscountRateGen:        "base_document_item.discount_rate_gen",
	UnitTaxAmount:          "base_document_item.unit_tax_amount",
	TotalTaxAmountGen:      "base_document_item.total_tax_amount_gen",
	TaxRateGen:             "base_document_item.tax_rate_gen",
	UnitShippingFees:       "base_document_item.unit_shipping_fees",
	TotalShippingFeesGen:   "base_document_item.total_shipping_fees_gen",
	FinalUnitPriceGen:      "base_document_item.final_unit_price_gen",
	TotalSalePriceGen:      "base_document_item.total_sale_price_gen",
}

// Generated where

type whereHelpernull_Int struct{ field string }

func (w whereHelpernull_Int) EQ(x null.Int) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Int) NEQ(x null.Int) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Int) LT(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Int) LTE(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Int) GT(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Int) GTE(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelpernull_Int) IN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelpernull_Int) NIN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

func (w whereHelpernull_Int) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Int) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

var BaseDocumentItemWhere = struct {
	ID                     whereHelperint
	CreatedAt              whereHelpertime_Time
	UpdatedAt              whereHelpertime_Time
	DeletedAt              whereHelpernull_Time
	BaseDocumentID         whereHelperint
	InventoryID            whereHelpernull_Int
	Quantity               whereHelpertypes_NullDecimal
	UnitPrice              whereHelpertypes_NullDecimal
	UnitDiscountAmount     whereHelpertypes_NullDecimal
	TotalDiscountAmountGen whereHelpertypes_NullDecimal
	DiscountRateGen        whereHelpertypes_NullDecimal
	UnitTaxAmount          whereHelpertypes_NullDecimal
	TotalTaxAmountGen      whereHelpertypes_NullDecimal
	TaxRateGen             whereHelpertypes_NullDecimal
	UnitShippingFees       whereHelpertypes_NullDecimal
	TotalShippingFeesGen   whereHelpertypes_NullDecimal
	FinalUnitPriceGen      whereHelpertypes_NullDecimal
	TotalSalePriceGen      whereHelpertypes_NullDecimal
}{
	ID:                     whereHelperint{field: "\"base\".\"base_document_item\".\"id\""},
	CreatedAt:              whereHelpertime_Time{field: "\"base\".\"base_document_item\".\"created_at\""},
	UpdatedAt:              whereHelpertime_Time{field: "\"base\".\"base_document_item\".\"updated_at\""},
	DeletedAt:              whereHelpernull_Time{field: "\"base\".\"base_document_item\".\"deleted_at\""},
	BaseDocumentID:         whereHelperint{field: "\"base\".\"base_document_item\".\"base_document_id\""},
	InventoryID:            whereHelpernull_Int{field: "\"base\".\"base_document_item\".\"inventory_id\""},
	Quantity:               whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"quantity\""},
	UnitPrice:              whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"unit_price\""},
	UnitDiscountAmount:     whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"unit_discount_amount\""},
	TotalDiscountAmountGen: whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"total_discount_amount_gen\""},
	DiscountRateGen:        whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"discount_rate_gen\""},
	UnitTaxAmount:          whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"unit_tax_amount\""},
	TotalTaxAmountGen:      whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"total_tax_amount_gen\""},
	TaxRateGen:             whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"tax_rate_gen\""},
	UnitShippingFees:       whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"unit_shipping_fees\""},
	TotalShippingFeesGen:   whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"total_shipping_fees_gen\""},
	FinalUnitPriceGen:      whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"final_unit_price_gen\""},
	TotalSalePriceGen:      whereHelpertypes_NullDecimal{field: "\"base\".\"base_document_item\".\"total_sale_price_gen\""},
}

// BaseDocumentItemRels is where relationship names are stored.
var BaseDocumentItemRels = struct {
	BaseDocument string
}{
	BaseDocument: "BaseDocument",
}

// baseDocumentItemR is where relationships are stored.
type baseDocumentItemR struct {
	BaseDocument *BaseDocument `boil:"BaseDocument" json:"BaseDocument" toml:"BaseDocument" yaml:"BaseDocument"`
}

// NewStruct creates a new relationship struct
func (*baseDocumentItemR) NewStruct() *baseDocumentItemR {
	return &baseDocumentItemR{}
}

func (r *baseDocumentItemR) GetBaseDocument() *BaseDocument {
	if r == nil {
		return nil
	}
	return r.BaseDocument
}

// baseDocumentItemL is where Load methods for each relationship are stored.
type baseDocumentItemL struct{}

var (
	baseDocumentItemAllColumns            = []string{"id", "created_at", "updated_at", "deleted_at", "base_document_id", "inventory_id", "quantity", "unit_price", "unit_discount_amount", "total_discount_amount_gen", "discount_rate_gen", "unit_tax_amount", "total_tax_amount_gen", "tax_rate_gen", "unit_shipping_fees", "total_shipping_fees_gen", "final_unit_price_gen", "total_sale_price_gen"}
	baseDocumentItemColumnsWithoutDefault = []string{"id", "created_at", "updated_at", "base_document_id"}
	baseDocumentItemColumnsWithDefault    = []string{"deleted_at", "inventory_id", "quantity", "unit_price", "unit_discount_amount", "total_discount_amount_gen", "discount_rate_gen", "unit_tax_amount", "total_tax_amount_gen", "tax_rate_gen", "unit_shipping_fees", "total_shipping_fees_gen", "final_unit_price_gen", "total_sale_price_gen"}
	baseDocumentItemPrimaryKeyColumns     = []string{"id"}
	baseDocumentItemGeneratedColumns      = []string{"total_discount_amount_gen", "discount_rate_gen", "total_tax_amount_gen", "tax_rate_gen", "total_shipping_fees_gen", "final_unit_price_gen", "total_sale_price_gen"}
)

type (
	// BaseDocumentItemSlice is an alias for a slice of pointers to BaseDocumentItem.
	// This should almost always be used instead of []BaseDocumentItem.
	BaseDocumentItemSlice []*BaseDocumentItem
	// BaseDocumentItemHook is the signature for custom BaseDocumentItem hook methods
	BaseDocumentItemHook func(context.Context, boil.ContextExecutor, *BaseDocumentItem) error

	baseDocumentItemQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	baseDocumentItemType                 = reflect.TypeOf(&BaseDocumentItem{})
	baseDocumentItemMapping              = queries.MakeStructMapping(baseDocumentItemType)
	baseDocumentItemPrimaryKeyMapping, _ = queries.BindMapping(baseDocumentItemType, baseDocumentItemMapping, baseDocumentItemPrimaryKeyColumns)
	baseDocumentItemInsertCacheMut       sync.RWMutex
	baseDocumentItemInsertCache          = make(map[string]insertCache)
	baseDocumentItemUpdateCacheMut       sync.RWMutex
	baseDocumentItemUpdateCache          = make(map[string]updateCache)
	baseDocumentItemUpsertCacheMut       sync.RWMutex
	baseDocumentItemUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

var baseDocumentItemAfterSelectMu sync.Mutex
var baseDocumentItemAfterSelectHooks []BaseDocumentItemHook

var baseDocumentItemBeforeInsertMu sync.Mutex
var baseDocumentItemBeforeInsertHooks []BaseDocumentItemHook
var baseDocumentItemAfterInsertMu sync.Mutex
var baseDocumentItemAfterInsertHooks []BaseDocumentItemHook

var baseDocumentItemBeforeUpdateMu sync.Mutex
var baseDocumentItemBeforeUpdateHooks []BaseDocumentItemHook
var baseDocumentItemAfterUpdateMu sync.Mutex
var baseDocumentItemAfterUpdateHooks []BaseDocumentItemHook

var baseDocumentItemBeforeDeleteMu sync.Mutex
var baseDocumentItemBeforeDeleteHooks []BaseDocumentItemHook
var baseDocumentItemAfterDeleteMu sync.Mutex
var baseDocumentItemAfterDeleteHooks []BaseDocumentItemHook

var baseDocumentItemBeforeUpsertMu sync.Mutex
var baseDocumentItemBeforeUpsertHooks []BaseDocumentItemHook
var baseDocumentItemAfterUpsertMu sync.Mutex
var baseDocumentItemAfterUpsertHooks []BaseDocumentItemHook

// doAfterSelectHooks executes all "after Select" hooks.
func (o *BaseDocumentItem) doAfterSelectHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemAfterSelectHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeInsertHooks executes all "before insert" hooks.
func (o *BaseDocumentItem) doBeforeInsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemBeforeInsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterInsertHooks executes all "after Insert" hooks.
func (o *BaseDocumentItem) doAfterInsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemAfterInsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeUpdateHooks executes all "before Update" hooks.
func (o *BaseDocumentItem) doBeforeUpdateHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemBeforeUpdateHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterUpdateHooks executes all "after Update" hooks.
func (o *BaseDocumentItem) doAfterUpdateHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemAfterUpdateHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeDeleteHooks executes all "before Delete" hooks.
func (o *BaseDocumentItem) doBeforeDeleteHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemBeforeDeleteHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterDeleteHooks executes all "after Delete" hooks.
func (o *BaseDocumentItem) doAfterDeleteHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemAfterDeleteHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeUpsertHooks executes all "before Upsert" hooks.
func (o *BaseDocumentItem) doBeforeUpsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemBeforeUpsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterUpsertHooks executes all "after Upsert" hooks.
func (o *BaseDocumentItem) doAfterUpsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range baseDocumentItemAfterUpsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// AddBaseDocumentItemHook registers your hook function for all future operations.
func AddBaseDocumentItemHook(hookPoint boil.HookPoint, baseDocumentItemHook BaseDocumentItemHook) {
	switch hookPoint {
	case boil.AfterSelectHook:
		baseDocumentItemAfterSelectMu.Lock()
		baseDocumentItemAfterSelectHooks = append(baseDocumentItemAfterSelectHooks, baseDocumentItemHook)
		baseDocumentItemAfterSelectMu.Unlock()
	case boil.BeforeInsertHook:
		baseDocumentItemBeforeInsertMu.Lock()
		baseDocumentItemBeforeInsertHooks = append(baseDocumentItemBeforeInsertHooks, baseDocumentItemHook)
		baseDocumentItemBeforeInsertMu.Unlock()
	case boil.AfterInsertHook:
		baseDocumentItemAfterInsertMu.Lock()
		baseDocumentItemAfterInsertHooks = append(baseDocumentItemAfterInsertHooks, baseDocumentItemHook)
		baseDocumentItemAfterInsertMu.Unlock()
	case boil.BeforeUpdateHook:
		baseDocumentItemBeforeUpdateMu.Lock()
		baseDocumentItemBeforeUpdateHooks = append(baseDocumentItemBeforeUpdateHooks, baseDocumentItemHook)
		baseDocumentItemBeforeUpdateMu.Unlock()
	case boil.AfterUpdateHook:
		baseDocumentItemAfterUpdateMu.Lock()
		baseDocumentItemAfterUpdateHooks = append(baseDocumentItemAfterUpdateHooks, baseDocumentItemHook)
		baseDocumentItemAfterUpdateMu.Unlock()
	case boil.BeforeDeleteHook:
		baseDocumentItemBeforeDeleteMu.Lock()
		baseDocumentItemBeforeDeleteHooks = append(baseDocumentItemBeforeDeleteHooks, baseDocumentItemHook)
		baseDocumentItemBeforeDeleteMu.Unlock()
	case boil.AfterDeleteHook:
		baseDocumentItemAfterDeleteMu.Lock()
		baseDocumentItemAfterDeleteHooks = append(baseDocumentItemAfterDeleteHooks, baseDocumentItemHook)
		baseDocumentItemAfterDeleteMu.Unlock()
	case boil.BeforeUpsertHook:
		baseDocumentItemBeforeUpsertMu.Lock()
		baseDocumentItemBeforeUpsertHooks = append(baseDocumentItemBeforeUpsertHooks, baseDocumentItemHook)
		baseDocumentItemBeforeUpsertMu.Unlock()
	case boil.AfterUpsertHook:
		baseDocumentItemAfterUpsertMu.Lock()
		baseDocumentItemAfterUpsertHooks = append(baseDocumentItemAfterUpsertHooks, baseDocumentItemHook)
		baseDocumentItemAfterUpsertMu.Unlock()
	}
}

// One returns a single baseDocumentItem record from the query.
func (q baseDocumentItemQuery) One(ctx context.Context, exec boil.ContextExecutor) (*BaseDocumentItem, error) {
	o := &BaseDocumentItem{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "base: failed to execute a one query for base_document_item")
	}

	if err := o.doAfterSelectHooks(ctx, exec); err != nil {
		return o, err
	}

	return o, nil
}

// All returns all BaseDocumentItem records from the query.
func (q baseDocumentItemQuery) All(ctx context.Context, exec boil.ContextExecutor) (BaseDocumentItemSlice, error) {
	var o []*BaseDocumentItem

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "base: failed to assign all query results to BaseDocumentItem slice")
	}

	if len(baseDocumentItemAfterSelectHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterSelectHooks(ctx, exec); err != nil {
				return o, err
			}
		}
	}

	return o, nil
}

// Count returns the count of all BaseDocumentItem records in the query.
func (q baseDocumentItemQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "base: failed to count base_document_item rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q baseDocumentItemQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "base: failed to check if base_document_item exists")
	}

	return count > 0, nil
}

// BaseDocument pointed to by the foreign key.
func (o *BaseDocumentItem) BaseDocument(mods ...qm.QueryMod) baseDocumentQuery {
	queryMods := []qm.QueryMod{
		qm.Where("\"id\" = ?", o.BaseDocumentID),
	}

	queryMods = append(queryMods, mods...)

	return BaseDocuments(queryMods...)
}

// LoadBaseDocument allows an eager lookup of values, cached into the
// loaded structs of the objects. This is for an N-1 relationship.
func (baseDocumentItemL) LoadBaseDocument(ctx context.Context, e boil.ContextExecutor, singular bool, maybeBaseDocumentItem interface{}, mods queries.Applicator) error {
	var slice []*BaseDocumentItem
	var object *BaseDocumentItem

	if singular {
		var ok bool
		object, ok = maybeBaseDocumentItem.(*BaseDocumentItem)
		if !ok {
			object = new(BaseDocumentItem)
			ok = queries.SetFromEmbeddedStruct(&object, &maybeBaseDocumentItem)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", object, maybeBaseDocumentItem))
			}
		}
	} else {
		s, ok := maybeBaseDocumentItem.(*[]*BaseDocumentItem)
		if ok {
			slice = *s
		} else {
			ok = queries.SetFromEmbeddedStruct(&slice, maybeBaseDocumentItem)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", slice, maybeBaseDocumentItem))
			}
		}
	}

	args := make(map[interface{}]struct{})
	if singular {
		if object.R == nil {
			object.R = &baseDocumentItemR{}
		}
		args[object.BaseDocumentID] = struct{}{}

	} else {
		for _, obj := range slice {
			if obj.R == nil {
				obj.R = &baseDocumentItemR{}
			}

			args[obj.BaseDocumentID] = struct{}{}

		}
	}

	if len(args) == 0 {
		return nil
	}

	argsSlice := make([]interface{}, len(args))
	i := 0
	for arg := range args {
		argsSlice[i] = arg
		i++
	}

	query := NewQuery(
		qm.From(`base.base_document`),
		qm.WhereIn(`base.base_document.id in ?`, argsSlice...),
	)
	if mods != nil {
		mods.Apply(query)
	}

	results, err := query.QueryContext(ctx, e)
	if err != nil {
		return errors.Wrap(err, "failed to eager load BaseDocument")
	}

	var resultSlice []*BaseDocument
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Wrap(err, "failed to bind eager loaded slice BaseDocument")
	}

	if err = results.Close(); err != nil {
		return errors.Wrap(err, "failed to close results of eager load for base_document")
	}
	if err = results.Err(); err != nil {
		return errors.Wrap(err, "error occurred during iteration of eager loaded relations for base_document")
	}

	if len(baseDocumentAfterSelectHooks) != 0 {
		for _, obj := range resultSlice {
			if err := obj.doAfterSelectHooks(ctx, e); err != nil {
				return err
			}
		}
	}

	if len(resultSlice) == 0 {
		return nil
	}

	if singular {
		foreign := resultSlice[0]
		object.R.BaseDocument = foreign
		if foreign.R == nil {
			foreign.R = &baseDocumentR{}
		}
		foreign.R.BaseDocumentItems = append(foreign.R.BaseDocumentItems, object)
		return nil
	}

	for _, local := range slice {
		for _, foreign := range resultSlice {
			if local.BaseDocumentID == foreign.ID {
				local.R.BaseDocument = foreign
				if foreign.R == nil {
					foreign.R = &baseDocumentR{}
				}
				foreign.R.BaseDocumentItems = append(foreign.R.BaseDocumentItems, local)
				break
			}
		}
	}

	return nil
}

// SetBaseDocument of the baseDocumentItem to the related item.
// Sets o.R.BaseDocument to related.
// Adds o to related.R.BaseDocumentItems.
func (o *BaseDocumentItem) SetBaseDocument(ctx context.Context, exec boil.ContextExecutor, insert bool, related *BaseDocument) error {
	var err error
	if insert {
		if err = related.Insert(ctx, exec, boil.Infer()); err != nil {
			return errors.Wrap(err, "failed to insert into foreign table")
		}
	}

	updateQuery := fmt.Sprintf(
		"UPDATE \"base\".\"base_document_item\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, []string{"base_document_id"}),
		strmangle.WhereClause("\"", "\"", 2, baseDocumentItemPrimaryKeyColumns),
	)
	values := []interface{}{related.ID, o.ID}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, updateQuery)
		fmt.Fprintln(writer, values)
	}
	if _, err = exec.ExecContext(ctx, updateQuery, values...); err != nil {
		return errors.Wrap(err, "failed to update local table")
	}

	o.BaseDocumentID = related.ID
	if o.R == nil {
		o.R = &baseDocumentItemR{
			BaseDocument: related,
		}
	} else {
		o.R.BaseDocument = related
	}

	if related.R == nil {
		related.R = &baseDocumentR{
			BaseDocumentItems: BaseDocumentItemSlice{o},
		}
	} else {
		related.R.BaseDocumentItems = append(related.R.BaseDocumentItems, o)
	}

	return nil
}

// BaseDocumentItems retrieves all the records using an executor.
func BaseDocumentItems(mods ...qm.QueryMod) baseDocumentItemQuery {
	mods = append(mods, qm.From("\"base\".\"base_document_item\""))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"\"base\".\"base_document_item\".*"})
	}

	return baseDocumentItemQuery{q}
}

// FindBaseDocumentItem retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindBaseDocumentItem(ctx context.Context, exec boil.ContextExecutor, iD int, selectCols ...string) (*BaseDocumentItem, error) {
	baseDocumentItemObj := &BaseDocumentItem{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from \"base\".\"base_document_item\" where \"id\"=$1", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(ctx, exec, baseDocumentItemObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "base: unable to select from base_document_item")
	}

	if err = baseDocumentItemObj.doAfterSelectHooks(ctx, exec); err != nil {
		return baseDocumentItemObj, err
	}

	return baseDocumentItemObj, nil
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *BaseDocumentItem) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("base: no base_document_item provided for insertion")
	}

	var err error
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if o.CreatedAt.IsZero() {
			o.CreatedAt = currTime
		}
		if o.UpdatedAt.IsZero() {
			o.UpdatedAt = currTime
		}
	}

	if err := o.doBeforeInsertHooks(ctx, exec); err != nil {
		return err
	}

	nzDefaults := queries.NonZeroDefaultSet(baseDocumentItemColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	baseDocumentItemInsertCacheMut.RLock()
	cache, cached := baseDocumentItemInsertCache[key]
	baseDocumentItemInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			baseDocumentItemAllColumns,
			baseDocumentItemColumnsWithDefault,
			baseDocumentItemColumnsWithoutDefault,
			nzDefaults,
		)
		wl = strmangle.SetComplement(wl, baseDocumentItemGeneratedColumns)

		cache.valueMapping, err = queries.BindMapping(baseDocumentItemType, baseDocumentItemMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(baseDocumentItemType, baseDocumentItemMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO \"base\".\"base_document_item\" (\"%s\") %%sVALUES (%s)%%s", strings.Join(wl, "\",\""), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO \"base\".\"base_document_item\" %sDEFAULT VALUES%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			queryReturning = fmt.Sprintf(" RETURNING \"%s\"", strings.Join(returnColumns, "\",\""))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}

	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}

	if err != nil {
		return errors.Wrap(err, "base: unable to insert into base_document_item")
	}

	if !cached {
		baseDocumentItemInsertCacheMut.Lock()
		baseDocumentItemInsertCache[key] = cache
		baseDocumentItemInsertCacheMut.Unlock()
	}

	return o.doAfterInsertHooks(ctx, exec)
}

// Update uses an executor to update the BaseDocumentItem.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *BaseDocumentItem) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		o.UpdatedAt = currTime
	}

	var err error
	if err = o.doBeforeUpdateHooks(ctx, exec); err != nil {
		return 0, err
	}
	key := makeCacheKey(columns, nil)
	baseDocumentItemUpdateCacheMut.RLock()
	cache, cached := baseDocumentItemUpdateCache[key]
	baseDocumentItemUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			baseDocumentItemAllColumns,
			baseDocumentItemPrimaryKeyColumns,
		)
		wl = strmangle.SetComplement(wl, baseDocumentItemGeneratedColumns)

		if !columns.IsWhitelist() {
			wl = strmangle.SetComplement(wl, []string{"created_at"})
		}
		if len(wl) == 0 {
			return 0, errors.New("base: unable to update base_document_item, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE \"base\".\"base_document_item\" SET %s WHERE %s",
			strmangle.SetParamNames("\"", "\"", 1, wl),
			strmangle.WhereClause("\"", "\"", len(wl)+1, baseDocumentItemPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(baseDocumentItemType, baseDocumentItemMapping, append(wl, baseDocumentItemPrimaryKeyColumns...))
		if err != nil {
			return 0, err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, values)
	}
	var result sql.Result
	result, err = exec.ExecContext(ctx, cache.query, values...)
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to update base_document_item row")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "base: failed to get rows affected by update for base_document_item")
	}

	if !cached {
		baseDocumentItemUpdateCacheMut.Lock()
		baseDocumentItemUpdateCache[key] = cache
		baseDocumentItemUpdateCacheMut.Unlock()
	}

	return rowsAff, o.doAfterUpdateHooks(ctx, exec)
}

// UpdateAll updates all rows with the specified column values.
func (q baseDocumentItemQuery) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	queries.SetUpdate(q.Query, cols)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to update all for base_document_item")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to retrieve rows affected for base_document_item")
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o BaseDocumentItemSlice) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	ln := int64(len(o))
	if ln == 0 {
		return 0, nil
	}

	if len(cols) == 0 {
		return 0, errors.New("base: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), baseDocumentItemPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE \"base\".\"base_document_item\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), len(colNames)+1, baseDocumentItemPrimaryKeyColumns, len(o)))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to update all in baseDocumentItem slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to retrieve rows affected all in update all baseDocumentItem")
	}
	return rowsAff, nil
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *BaseDocumentItem) Upsert(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns, opts ...UpsertOptionFunc) error {
	if o == nil {
		return errors.New("base: no base_document_item provided for upsert")
	}
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if o.CreatedAt.IsZero() {
			o.CreatedAt = currTime
		}
		o.UpdatedAt = currTime
	}

	if err := o.doBeforeUpsertHooks(ctx, exec); err != nil {
		return err
	}

	nzDefaults := queries.NonZeroDefaultSet(baseDocumentItemColumnsWithDefault, o)

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	if updateOnConflict {
		buf.WriteByte('t')
	} else {
		buf.WriteByte('f')
	}
	buf.WriteByte('.')
	for _, c := range conflictColumns {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	baseDocumentItemUpsertCacheMut.RLock()
	cache, cached := baseDocumentItemUpsertCache[key]
	baseDocumentItemUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, _ := insertColumns.InsertColumnSet(
			baseDocumentItemAllColumns,
			baseDocumentItemColumnsWithDefault,
			baseDocumentItemColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			baseDocumentItemAllColumns,
			baseDocumentItemPrimaryKeyColumns,
		)

		insert = strmangle.SetComplement(insert, baseDocumentItemGeneratedColumns)
		update = strmangle.SetComplement(update, baseDocumentItemGeneratedColumns)

		if updateOnConflict && len(update) == 0 {
			return errors.New("base: unable to upsert base_document_item, could not build update column list")
		}

		ret := strmangle.SetComplement(baseDocumentItemAllColumns, strmangle.SetIntersect(insert, update))

		conflict := conflictColumns
		if len(conflict) == 0 && updateOnConflict && len(update) != 0 {
			if len(baseDocumentItemPrimaryKeyColumns) == 0 {
				return errors.New("base: unable to upsert base_document_item, could not build conflict column list")
			}

			conflict = make([]string, len(baseDocumentItemPrimaryKeyColumns))
			copy(conflict, baseDocumentItemPrimaryKeyColumns)
		}
		cache.query = buildUpsertQueryPostgres(dialect, "\"base\".\"base_document_item\"", updateOnConflict, ret, update, conflict, insert, opts...)

		cache.valueMapping, err = queries.BindMapping(baseDocumentItemType, baseDocumentItemMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(baseDocumentItemType, baseDocumentItemMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(returns...)
		if errors.Is(err, sql.ErrNoRows) {
			err = nil // Postgres doesn't return anything when there's no update
		}
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}
	if err != nil {
		return errors.Wrap(err, "base: unable to upsert base_document_item")
	}

	if !cached {
		baseDocumentItemUpsertCacheMut.Lock()
		baseDocumentItemUpsertCache[key] = cache
		baseDocumentItemUpsertCacheMut.Unlock()
	}

	return o.doAfterUpsertHooks(ctx, exec)
}

// Delete deletes a single BaseDocumentItem record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *BaseDocumentItem) Delete(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if o == nil {
		return 0, errors.New("base: no BaseDocumentItem provided for delete")
	}

	if err := o.doBeforeDeleteHooks(ctx, exec); err != nil {
		return 0, err
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), baseDocumentItemPrimaryKeyMapping)
	sql := "DELETE FROM \"base\".\"base_document_item\" WHERE \"id\"=$1"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to delete from base_document_item")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "base: failed to get rows affected by delete for base_document_item")
	}

	if err := o.doAfterDeleteHooks(ctx, exec); err != nil {
		return 0, err
	}

	return rowsAff, nil
}

// DeleteAll deletes all matching rows.
func (q baseDocumentItemQuery) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if q.Query == nil {
		return 0, errors.New("base: no baseDocumentItemQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to delete all from base_document_item")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "base: failed to get rows affected by deleteall for base_document_item")
	}

	return rowsAff, nil
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o BaseDocumentItemSlice) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	if len(baseDocumentItemBeforeDeleteHooks) != 0 {
		for _, obj := range o {
			if err := obj.doBeforeDeleteHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), baseDocumentItemPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM \"base\".\"base_document_item\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, baseDocumentItemPrimaryKeyColumns, len(o))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "base: unable to delete all from baseDocumentItem slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "base: failed to get rows affected by deleteall for base_document_item")
	}

	if len(baseDocumentItemAfterDeleteHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterDeleteHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	return rowsAff, nil
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *BaseDocumentItem) Reload(ctx context.Context, exec boil.ContextExecutor) error {
	ret, err := FindBaseDocumentItem(ctx, exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BaseDocumentItemSlice) ReloadAll(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := BaseDocumentItemSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), baseDocumentItemPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT \"base\".\"base_document_item\".* FROM \"base\".\"base_document_item\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, baseDocumentItemPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(ctx, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "base: unable to reload all in BaseDocumentItemSlice")
	}

	*o = slice

	return nil
}

// BaseDocumentItemExists checks if the BaseDocumentItem row exists.
func BaseDocumentItemExists(ctx context.Context, exec boil.ContextExecutor, iD int) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from \"base\".\"base_document_item\" where \"id\"=$1 limit 1)"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, iD)
	}
	row := exec.QueryRowContext(ctx, sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "base: unable to check if base_document_item exists")
	}

	return exists, nil
}

// Exists checks if the BaseDocumentItem row exists.
func (o *BaseDocumentItem) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	return BaseDocumentItemExists(ctx, exec, o.ID)
}
